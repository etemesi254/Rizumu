dnr_dataset:
  bandspit_rnn:
    # the mix name, contains a mixture of the audio file
    mix_name: "mix"
    # the labels from the mix, this is the order in
    # which they will be loaded so the
    # dataset loader will return a tuple of tensor
    # containing (mix,speech,vocals and sfx)
    labels: [ "mix", "speech" ]
    output_label: "speech"
    # model configurations
    dataset_dir: "/Users/etemesi/Datasets/dnr_v2/cv"
    # batch size of the dataset in training
    batch_size: 1
    # whether to shuffle data when training
    shuffle: true
    # number of epochs to go
    num_epochs: 52
    # whether  we start our model from a previously saved checkpoint or a new model
    checkpoint: false
    # if checkpoint is true, start from this checkpoint path
    checkpoint_path: "/Users/etemesi/PycharmProjects/Rizumu/chekpoints/bandspitrnn_logs/epoch=38-step=1248.ckpt"
    log_dir: "./chekpoints/bandspitrnn_logs"

    model_config:
      # sample rate
      sr: 44100
      # n_fft window size
      n_fft: 2048
      # rough bandspit configuration
      bandsplits:
        [ [ 1000, 100 ], [ 4000, 400 ], [ 8000, 600 ], [ 16000, 2000 ], [ 20000, 4000 ] ]
      complex_as_channel: true
      # DNR config is channel
      is_mono: true
      # either `rnn` or `att`
      bottleneck_layer: "rnn"
      # affects rnn layers.
      fc_dim: 128
      rnn_dim: 256
      rnn_type: "LSTM"
      t_timesteps: 5168 # 1 minute stft with 2048 generates the following timestep
      bidirectional: true
      num_layers: 1
      mlp_dim: 512
      return_mask: false

  openunmix:
    mix_name: "mix"
    # the labels from the mix, this is the order in
    # which they will be loaded so the
    # dataset loader will return a tuple of tensor
    # containing (mix,speech,vocals and sfx)
    labels: [ "mix", "speech" ]
    output_label: "speech"
    # model configurations
    dataset_dir: "/Volumes/Untitled/DNR/dnr/dnr/dnr/tr"
    # batch size of the dataset in training
    batch_size: 1
    # whether to shuffle data when training
    shuffle: true
    # number of epochs to go
    num_epochs: 52
    # whether  we start our model from a previously saved checkpoint or a new model
    checkpoint: false
    # if checkpoint is true, start from this checkpoint path
    checkpoint_path: "/Users/etemesi/PycharmProjects/Rizumu/lightning_logs/version_4/checkpoints/epoch=49-step=1600.ckpt"
    log_dir: "./chekpoints/openunmix_logs"
    # if use DCT is true we preprocess the audio by applying a dct pre-filter before we contine
    use_dct: False
    # quantizer value if we are using dct preprocessing
    quantizer: 2000
    # number of bi-LSTM layers.
    nb_layers: 1
    # dataset configurations
    dataset_config:
      nb_bins: 2049
      nb_channels: 1
  rizumu:
    # file containing the mix
    mix_name: "mix"
    # files to load from each directory
    labels: [ "mix", "speech" ]
    # the output of the file we want to etract
    output_label: "speech"
    # directories containing train and test sets
    training_set: "/Volumes/Untitled/DNR/dnr_v2/dnr.part/dnr_v2/tr"
    testing_set: "/Volumes/Untitled/DNR/dnr_v2/dnr.part/dnr_v2/tt"
    validation_set: "/Volumes/Untitled/DNR/dnr/dnr/dnr/cv"
    # number of batches
    batch_size: 1
    # whether to shuffle training data
    shuffle: true
    # number of epochs for the training part
    num_epochs: 50
    # Whether training resumes from a previous steps or starts from scratch
    checkpoint: True
    # If we are starting from a checkpoint, the path to that checkpoint
    checkpoint_path: "/Users/etemesi/PycharmProjects/Rizumu/chekpoints/rizumu_logs/epoch=49-step=53350.ckpt"
    # Log directories
    log_dir: "./chekpoints/rizumu_logs"
    # whether DCT is applied as a preprocessing step
    use_dct: True
    quantizer: 2500
    # number of LSTM layers we stack on top of each other
    lstm_layers: 2
    # how many bands to split the audio spectrogram in
    num_splits: 1
    # hidden size of the LSTM layer
    hidden_size: 512
